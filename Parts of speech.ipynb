{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install nltk pandas"
      ],
      "metadata": {
        "id": "duLl5Vkml-ur",
        "outputId": "f104a439-8e92-4699-c68d-676b0e0c489e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from collections import Counter\n",
        "\n",
        "# Ensure you have the necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('mail_data.csv')\n",
        "\n",
        "# Function to map POS tags to their full names\n",
        "def map_pos_to_full_name(tag):\n",
        "    pos_full_names = {\n",
        "        'CC': 'Coordinating conjunction', 'CD': 'Cardinal number', 'DT': 'Determiner', 'EX': 'Existential there',\n",
        "        'FW': 'Foreign word', 'IN': 'Preposition or subordinating conjunction', 'JJ': 'Adjective',\n",
        "        'JJR': 'Adjective, comparative', 'JJS': 'Adjective, superlative', 'LS': 'List item marker',\n",
        "        'MD': 'Modal', 'NN': 'Noun, singular or mass', 'NNS': 'Noun, plural', 'NNP': 'Proper noun, singular',\n",
        "        'NNPS': 'Proper noun, plural', 'PDT': 'Predeterminer', 'POS': 'Possessive ending', 'PRP': 'Personal pronoun',\n",
        "        'PRP$': 'Possessive pronoun', 'RB': 'Adverb', 'RBR': 'Adverb, comparative', 'RBS': 'Adverb, superlative',\n",
        "        'RP': 'Particle', 'SYM': 'Symbol', 'TO': 'to', 'UH': 'Interjection', 'VB': 'Verb, base form',\n",
        "        'VBD': 'Verb, past tense', 'VBG': 'Verb, gerund or present participle', 'VBN': 'Verb, past participle',\n",
        "        'VBP': 'Verb, non-3rd person singular present', 'VBZ': 'Verb, 3rd person singular present',\n",
        "        'WDT': 'Wh-determiner', 'WP': 'Wh-pronoun', 'WP$': 'Possessive wh-pronoun', 'WRB': 'Wh-adverb'\n",
        "    }\n",
        "    return pos_full_names.get(tag, tag)\n",
        "\n",
        "# Function to extract POS tags and their counts with full names\n",
        "def pos_features(Message):\n",
        "    tokens = word_tokenize(Message)\n",
        "    pos_tags = pos_tag(tokens)\n",
        "    pos_counts = Counter(map_pos_to_full_name(tag) for word, tag in pos_tags)\n",
        "    return pos_counts\n",
        "\n",
        "# Function to tag each word with its POS and map to full names\n",
        "def tag_words_with_pos(Message):\n",
        "    tokens = word_tokenize(Message)\n",
        "    pos_tags = pos_tag(tokens)\n",
        "    tagged_words = [(word, map_pos_to_full_name(tag)) for word, tag in pos_tags]\n",
        "    return tagged_words\n",
        "\n",
        "# Apply the pos_features function to the 'Processed_Message' column\n",
        "df['POS_Tags'] = df['Message'].apply(pos_features)\n",
        "\n",
        "# Apply the tag_words_with_pos function to the 'Processed_Message' column\n",
        "df['Tagged_Words'] = df['Message'].apply(tag_words_with_pos)\n",
        "\n",
        "# Create a DataFrame with POS tag features\n",
        "pos_df = pd.DataFrame(df['POS_Tags'].tolist()).fillna(0)\n",
        "\n",
        "# Combine the original DataFrame with the POS features DataFrame\n",
        "df = pd.concat([df, pos_df], axis=1).drop(columns=['POS_Tags'])\n",
        "\n",
        "# Save the enhanced DataFrame to a new CSV file\n",
        "df.to_csv('enhanced_mail_data_with_tagged_words.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the enhanced DataFrame\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "5wi9g2YEp46D",
        "outputId": "7b884a1d-f834-4666-c7bc-f5e922954412",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Category                                            Message  \\\n",
            "0      ham  Go until jurong point, crazy.. Available only ...   \n",
            "1      ham                      Ok lar... Joking wif u oni...   \n",
            "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
            "3      ham  U dun say so early hor... U c already then say...   \n",
            "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
            "\n",
            "                                        Tagged_Words  Proper noun, singular  \\\n",
            "0  [(Go, Proper noun, singular), (until, Preposit...                    3.0   \n",
            "1  [(Ok, Proper noun, singular), (lar, Noun, sing...                    2.0   \n",
            "2  [(Free, Adjective), (entry, Noun, singular or ...                    6.0   \n",
            "3  [(U, Adjective), (dun, Noun, plural), (say, Ve...                    1.0   \n",
            "4  [(Nah, Proper noun, singular), (I, Personal pr...                    1.0   \n",
            "\n",
            "   Preposition or subordinating conjunction  Adjective  \\\n",
            "0                                       2.0        3.0   \n",
            "1                                       0.0        1.0   \n",
            "2                                       1.0        4.0   \n",
            "3                                       0.0        2.0   \n",
            "4                                       1.0        0.0   \n",
            "\n",
            "   Noun, singular or mass    ,  Adverb  Foreign word  ...  Predeterminer    #  \\\n",
            "0                     7.0  1.0     3.0           1.0  ...            0.0  0.0   \n",
            "1                     2.0  0.0     0.0           0.0  ...            0.0  0.0   \n",
            "2                     7.0  0.0     0.0           0.0  ...            0.0  0.0   \n",
            "3                     1.0  0.0     3.0           0.0  ...            0.0  0.0   \n",
            "4                     0.0  1.0     3.0           0.0  ...            0.0  0.0   \n",
            "\n",
            "    ``   ''  Proper noun, plural  Adverb, comparative  Adverb, superlative  \\\n",
            "0  0.0  0.0                  0.0                  0.0                  0.0   \n",
            "1  0.0  0.0                  0.0                  0.0                  0.0   \n",
            "2  0.0  0.0                  0.0                  0.0                  0.0   \n",
            "3  0.0  0.0                  0.0                  0.0                  0.0   \n",
            "4  0.0  0.0                  0.0                  0.0                  0.0   \n",
            "\n",
            "   Symbol  Possessive wh-pronoun  List item marker  \n",
            "0     0.0                    0.0               0.0  \n",
            "1     0.0                    0.0               0.0  \n",
            "2     0.0                    0.0               0.0  \n",
            "3     0.0                    0.0               0.0  \n",
            "4     0.0                    0.0               0.0  \n",
            "\n",
            "[5 rows x 48 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from collections import Counter\n",
        "\n",
        "# Ensure you have the necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('mail_data.csv')\n",
        "\n",
        "# Function to map POS tags to their full names\n",
        "def map_pos_to_full_name(tag):\n",
        "    pos_full_names = {\n",
        "        'CC': 'Coordinating conjunction', 'CD': 'Cardinal number', 'DT': 'Determiner', 'EX': 'Existential there',\n",
        "        'FW': 'Foreign word', 'IN': 'Preposition or subordinating conjunction', 'JJ': 'Adjective',\n",
        "        'JJR': 'Adjective, comparative', 'JJS': 'Adjective, superlative', 'LS': 'List item marker',\n",
        "        'MD': 'Modal', 'NN': 'Noun, singular or mass', 'NNS': 'Noun, plural', 'NNP': 'Proper noun, singular',\n",
        "        'NNPS': 'Proper noun, plural', 'PDT': 'Predeterminer', 'POS': 'Possessive ending', 'PRP': 'Personal pronoun',\n",
        "        'PRP$': 'Possessive pronoun', 'RB': 'Adverb', 'RBR': 'Adverb, comparative', 'RBS': 'Adverb, superlative',\n",
        "        'RP': 'Particle', 'SYM': 'Symbol', 'TO': 'to', 'UH': 'Interjection', 'VB': 'Verb, base form',\n",
        "        'VBD': 'Verb, past tense', 'VBG': 'Verb, gerund or present participle', 'VBN': 'Verb, past participle',\n",
        "        'VBP': 'Verb, non-3rd person singular present', 'VBZ': 'Verb, 3rd person singular present',\n",
        "        'WDT': 'Wh-determiner', 'WP': 'Wh-pronoun', 'WP$': 'Possessive wh-pronoun', 'WRB': 'Wh-adverb'\n",
        "    }\n",
        "    return pos_full_names.get(tag, tag)\n",
        "\n",
        "# Function to extract POS tags and their counts with full names\n",
        "def pos_features(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    pos_tags = pos_tag(tokens)\n",
        "    pos_counts = Counter(map_pos_to_full_name(tag) for word, tag in pos_tags)\n",
        "    return pos_counts\n",
        "\n",
        "# Apply the pos_features function to the 'Processed_Message' column\n",
        "df['POS_Tags'] = df['Message'].apply(pos_features)\n",
        "\n",
        "# Create a DataFrame with POS tag features\n",
        "pos_df = pd.DataFrame(df['POS_Tags'].tolist()).fillna(0)\n",
        "\n",
        "# Combine the original DataFrame with the POS features DataFrame\n",
        "df = pd.concat([df, pos_df], axis=1).drop(columns=['POS_Tags'])\n",
        "\n",
        "# Save the enhanced DataFrame to a new CSV file\n",
        "df.to_csv('11enhanced_mail_data_with_pos_features.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the enhanced DataFrame\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "IwvG0tPxnUm8",
        "outputId": "419466db-a0e8-4c3c-d7ac-80337e788af4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Category                                            Message  \\\n",
            "0      ham  Go until jurong point, crazy.. Available only ...   \n",
            "1      ham                      Ok lar... Joking wif u oni...   \n",
            "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
            "3      ham  U dun say so early hor... U c already then say...   \n",
            "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
            "\n",
            "   Proper noun, singular  Preposition or subordinating conjunction  Adjective  \\\n",
            "0                    3.0                                       2.0        3.0   \n",
            "1                    2.0                                       0.0        1.0   \n",
            "2                    6.0                                       1.0        4.0   \n",
            "3                    1.0                                       0.0        2.0   \n",
            "4                    1.0                                       1.0        0.0   \n",
            "\n",
            "   Noun, singular or mass    ,  Adverb  Foreign word    :  ...  Predeterminer  \\\n",
            "0                     7.0  1.0     3.0           1.0  2.0  ...            0.0   \n",
            "1                     2.0  0.0     0.0           0.0  2.0  ...            0.0   \n",
            "2                     7.0  0.0     0.0           0.0  0.0  ...            0.0   \n",
            "3                     1.0  0.0     3.0           0.0  2.0  ...            0.0   \n",
            "4                     0.0  1.0     3.0           0.0  0.0  ...            0.0   \n",
            "\n",
            "     #   ``   ''  Proper noun, plural  Adverb, comparative  \\\n",
            "0  0.0  0.0  0.0                  0.0                  0.0   \n",
            "1  0.0  0.0  0.0                  0.0                  0.0   \n",
            "2  0.0  0.0  0.0                  0.0                  0.0   \n",
            "3  0.0  0.0  0.0                  0.0                  0.0   \n",
            "4  0.0  0.0  0.0                  0.0                  0.0   \n",
            "\n",
            "   Adverb, superlative  Symbol  Possessive wh-pronoun  List item marker  \n",
            "0                  0.0     0.0                    0.0               0.0  \n",
            "1                  0.0     0.0                    0.0               0.0  \n",
            "2                  0.0     0.0                    0.0               0.0  \n",
            "3                  0.0     0.0                    0.0               0.0  \n",
            "4                  0.0     0.0                    0.0               0.0  \n",
            "\n",
            "[5 rows x 47 columns]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}